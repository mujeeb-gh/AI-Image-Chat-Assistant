{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype 2 - Current Working Application ✔️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -Second attempt at facial recognition similarity checker.\n",
    "#### -Uses multiple face encodings from the DB instead of images in local directory.\n",
    "#### -Database integration ✔️\n",
    "#### -Individual information stored and diplayed ✔️\n",
    "#### -Real time webcam feedback with similarity percentage ✔️ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortcomings\n",
    "### -Extremely slow real time feedback using the webcam\n",
    "##### The code is slow because it has to retrieve the face encodings from the database as BLOB then convert to a numpy array, then perform various loops and calculations on thousands of numbers and it has to show the results on the webcam feed. \n",
    "###### One way to optimize the code is to use a pre-trained deep learning model for face recognition. Deepface is a Python library that covers Keras-based face recognition models and can recognize faces in real-time. According to experiments, VGG-Face is the fastest to build\n",
    "\n",
    "###### Another option is to use a combination of deep learning and support vector machines (SVMs) for face recognition. This approach involves training a deep learning model to extract features from faces, then using an SVM to classify the faces based on those features\n",
    "###### Try changing Database system to MySQL or MongoDB\n",
    "###### - MySQL is a relational database management system that stores data in tables containing rows and columns, while MongoDB is a document-based NoSQL database that stores data in JSON-like documents. Face recognition requires storing multidimensional arrays and making calculations over them, which can be problematic for large data sets with millions of data points. MongoDB is well-suited for real-time data processing and big data operations, while MySQL is more popular for traditional web applications\n",
    "\n",
    "###### This approach can achieve high accuracy and fast recognition times. Additionally, the code can be optimized by using multi-threading or multiprocessing to perform the face recognition and database queries in parallel, which can significantly reduce the execution time.\n",
    "\n",
    "###### recommended by perplexity.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already exists in the database\n",
      "Data already exists in the database\n",
      "Data already exists in the database\n",
      "Data already exists in the database\n",
      "Data already exists in the database\n",
      "Error: No face found in the image: Known_Faces/Semilore\\0fb76587-5216-11ee-84d9-dc7196b8973b.jpg\n",
      "Data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "import face_recognition, pickle, cv2, sqlite3, os, numpy as np\n",
    "\n",
    "DATABASE_NAME = \"face_data.db\"\n",
    "KNOWN_FACES_DIR = \"Known_Faces\"\n",
    "\n",
    "def create_database():\n",
    "    # Connect to the database or create it if it doesn't exist\n",
    "    conn = sqlite3.connect(DATABASE_NAME)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Create a table to store face data if it doesn't exist\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS face_data (\n",
    "            id INTEGER PRIMARY KEY,\n",
    "            email TEXT UNIQUE,\n",
    "            name TEXT UNIQUE,\n",
    "            age INTEGER,\n",
    "            occupation TEXT,\n",
    "            face_encoding BLOB,\n",
    "            image_folder TEXT\n",
    "        )\n",
    "    ''')\n",
    "\n",
    "    # Save the changes and close the connection\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def encode_image(image_path):\n",
    "    image = face_recognition.load_image_file(image_path)\n",
    "    face_encodings = face_recognition.face_encodings(image)\n",
    "\n",
    "    if len(face_encodings) > 0:\n",
    "        return face_encodings[0]  # Only encode the first face found in the image\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def check_existing_data(email, name, face_encoding, image_folder):\n",
    "    try:\n",
    "        # Connect to the database\n",
    "        conn = sqlite3.connect(DATABASE_NAME)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Check if the email, name, face encoding, or image path already exists in the database\n",
    "        cursor.execute('''\n",
    "            SELECT * FROM face_data WHERE email=? OR name=? OR face_encoding=? OR image_folder=?\n",
    "        ''', (email, name, face_encoding, image_folder))\n",
    "\n",
    "        existing_data = cursor.fetchone()\n",
    "\n",
    "        # Close the connection\n",
    "        conn.close()\n",
    "\n",
    "        return existing_data\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        print(\"Error while checking existing data:\", e)\n",
    "        return None\n",
    "\n",
    "def insert_data(email, name, age, occupation, face_encoding, image_folder):\n",
    "    try:\n",
    "        # Check if the data already exists\n",
    "        existing_data = check_existing_data(email, name, face_encoding, image_folder)\n",
    "        if existing_data:\n",
    "            print(\"Data already exists in the database\")\n",
    "            return\n",
    "\n",
    "        # Connect to the database\n",
    "        conn = sqlite3.connect(DATABASE_NAME)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Insert data into the table\n",
    "        cursor.execute('''\n",
    "            INSERT INTO face_data (email, name, age, occupation, face_encoding, image_folder)\n",
    "            VALUES (?, ?, ?, ?, ?, ?)\n",
    "        ''', (email, name, age, occupation, face_encoding, image_folder))\n",
    "\n",
    "        # Save the changes and close the connection\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "\n",
    "        print(\"Data inserted successfully!\")\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        print(\"Error while inserting data:\", e)\n",
    "\n",
    "def main():\n",
    "    create_database()\n",
    "\n",
    "    # Sample data to insert (replace this with actual data and image paths)\n",
    "    data = [\n",
    "        {\n",
    "            \"email\": \"toluwaniojof@gmail.com\",\n",
    "            \"name\": \"Ojo Toluwani\",\n",
    "            \"age\": 20,\n",
    "            \"occupation\": \"Mobile Developer\",\n",
    "            \"image_folder\": \"Known_Faces/Tolu\"\n",
    "        },\n",
    "        {\n",
    "            \"email\": \"john.doe@yahoo.com\",\n",
    "            \"name\": \"Balogun Olamide\",\n",
    "            \"age\": 19,\n",
    "            \"occupation\": \"Data Scientist\",\n",
    "            \"image_folder\": \"Known_Faces/Olamide\"\n",
    "        },\n",
    "        {\n",
    "            \"email\": \"adisadavid@gmail.com\",\n",
    "            \"name\": \"Adisa David\",\n",
    "            \"age\": 20,\n",
    "            \"occupation\": \"Full Stack Developer\",\n",
    "            \"image_folder\": \"Known_Faces/David\"\n",
    "        },\n",
    "        {\n",
    "            \"email\": \"afolabiife@gmail.com\",\n",
    "            \"name\": \"Afolabi Oluwaife\",\n",
    "            \"age\": 19,\n",
    "            \"occupation\": \"Frontend Developer\",\n",
    "            \"image_folder\": \"Known_Faces/Ife\"\n",
    "        },\n",
    "        # {\n",
    "        #     \"email\": \"aalimah@gmail.com\",\n",
    "        #     \"name\": \"Aalimah\",\n",
    "        #     \"age\": 10,\n",
    "        #     \"occupation\": \"Senior Prefect\",\n",
    "        #     \"image_folder\": \"Known_Faces/Aalimah\"\n",
    "        # },\n",
    "        {\n",
    "            \"email\": \"semilore@gmail.com\",\n",
    "            \"name\": \"Oniyide Semilore\",\n",
    "            \"age\": 27,\n",
    "            \"occupation\": \"Software Intern\",\n",
    "            \"image_folder\": \"Known_Faces/Semilore\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    for item in data:\n",
    "        email = item[\"email\"]\n",
    "        name = item[\"name\"]\n",
    "        age = item[\"age\"]\n",
    "        occupation = item[\"occupation\"]\n",
    "        image_folder = item[\"image_folder\"]\n",
    "        image_paths = [os.path.join(image_folder, image) for image in os.listdir(image_folder) if image.lower().endswith('.jpg')]\n",
    "        face_encoding_list = []\n",
    "        \n",
    "        for image_path in image_paths:\n",
    "            face_encoding = encode_image(image_path)\n",
    "            if face_encoding is not None:\n",
    "                face_encoding_list.append(face_encoding)\n",
    "            else:\n",
    "                print(f\"Error: No face found in the image: {image_path}\")\n",
    "                # Delete any image with no face encoding\n",
    "                os.remove(image_path)\n",
    "        # Serializing the array, because it's too large, using pickle\n",
    "        blob_face_encoding = pickle.dumps(np.array(face_encoding_list))\n",
    "        insert_data(email, name, age, occupation, blob_face_encoding, image_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Face Recognition and DB info retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\olami\\Documents\\E Process\\DS_ML_AI\\Computer Vision\\AI-Enabled Image Search and Conversation Assistant\\prototype_2_faceRecog.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/olami/Documents/E%20Process/DS_ML_AI/Computer%20Vision/AI-Enabled%20Image%20Search%20and%20Conversation%20Assistant/prototype_2_faceRecog.ipynb#X10sZmlsZQ%3D%3D?line=118'>119</a>\u001b[0m     cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/olami/Documents/E%20Process/DS_ML_AI/Computer%20Vision/AI-Enabled%20Image%20Search%20and%20Conversation%20Assistant/prototype_2_faceRecog.ipynb#X10sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/olami/Documents/E%20Process/DS_ML_AI/Computer%20Vision/AI-Enabled%20Image%20Search%20and%20Conversation%20Assistant/prototype_2_faceRecog.ipynb#X10sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m     main()\n",
      "\u001b[1;32mc:\\Users\\olami\\Documents\\E Process\\DS_ML_AI\\Computer Vision\\AI-Enabled Image Search and Conversation Assistant\\prototype_2_faceRecog.ipynb Cell 8\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/olami/Documents/E%20Process/DS_ML_AI/Computer%20Vision/AI-Enabled%20Image%20Search%20and%20Conversation%20Assistant/prototype_2_faceRecog.ipynb#X10sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m faces \u001b[39m=\u001b[39m face_cascade\u001b[39m.\u001b[39mdetectMultiScale(gray_frame, scaleFactor\u001b[39m=\u001b[39m\u001b[39m1.1\u001b[39m, minNeighbors\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, minSize\u001b[39m=\u001b[39m(\u001b[39m30\u001b[39m, \u001b[39m30\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/olami/Documents/E%20Process/DS_ML_AI/Computer%20Vision/AI-Enabled%20Image%20Search%20and%20Conversation%20Assistant/prototype_2_faceRecog.ipynb#X10sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39mfor\u001b[39;00m (x, y, w, h) \u001b[39min\u001b[39;00m faces:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/olami/Documents/E%20Process/DS_ML_AI/Computer%20Vision/AI-Enabled%20Image%20Search%20and%20Conversation%20Assistant/prototype_2_faceRecog.ipynb#X10sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     face_encoding \u001b[39m=\u001b[39m face_recognition\u001b[39m.\u001b[39;49mface_encodings(frame, [(y, x \u001b[39m+\u001b[39;49m w, y \u001b[39m+\u001b[39;49m h, x)])[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/olami/Documents/E%20Process/DS_ML_AI/Computer%20Vision/AI-Enabled%20Image%20Search%20and%20Conversation%20Assistant/prototype_2_faceRecog.ipynb#X10sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     name \u001b[39m=\u001b[39m recognize_person(face_encoding, known_face_encodings)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/olami/Documents/E%20Process/DS_ML_AI/Computer%20Vision/AI-Enabled%20Image%20Search%20and%20Conversation%20Assistant/prototype_2_faceRecog.ipynb#X10sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     \u001b[39mif\u001b[39;00m name:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/olami/Documents/E%20Process/DS_ML_AI/Computer%20Vision/AI-Enabled%20Image%20Search%20and%20Conversation%20Assistant/prototype_2_faceRecog.ipynb#X10sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m         \u001b[39m# Calculate similarity percentage\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\olami\\anaconda3\\lib\\site-packages\\face_recognition\\api.py:214\u001b[0m, in \u001b[0;36mface_encodings\u001b[1;34m(face_image, known_face_locations, num_jitters, model)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39mGiven an image, return the 128-dimension face encoding for each face in the image.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[39m:return: A list of 128-dimensional face encodings (one for each face in the image)\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    213\u001b[0m raw_landmarks \u001b[39m=\u001b[39m _raw_face_landmarks(face_image, known_face_locations, model)\n\u001b[1;32m--> 214\u001b[0m \u001b[39mreturn\u001b[39;00m [np\u001b[39m.\u001b[39marray(face_encoder\u001b[39m.\u001b[39mcompute_face_descriptor(face_image, raw_landmark_set, num_jitters)) \u001b[39mfor\u001b[39;00m raw_landmark_set \u001b[39min\u001b[39;00m raw_landmarks]\n",
      "File \u001b[1;32mc:\\Users\\olami\\anaconda3\\lib\\site-packages\\face_recognition\\api.py:214\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39mGiven an image, return the 128-dimension face encoding for each face in the image.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[39m:return: A list of 128-dimensional face encodings (one for each face in the image)\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    213\u001b[0m raw_landmarks \u001b[39m=\u001b[39m _raw_face_landmarks(face_image, known_face_locations, model)\n\u001b[1;32m--> 214\u001b[0m \u001b[39mreturn\u001b[39;00m [np\u001b[39m.\u001b[39;49marray(face_encoder\u001b[39m.\u001b[39;49mcompute_face_descriptor(face_image, raw_landmark_set, num_jitters)) \u001b[39mfor\u001b[39;00m raw_landmark_set \u001b[39min\u001b[39;00m raw_landmarks]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import face_recognition, pickle, cv2, sqlite3, time, os, numpy as np\n",
    "\n",
    "DATABASE_NAME = \"face_data.db\"\n",
    "\n",
    "def load_known_face_encodings():\n",
    "    known_face_encodings = {}\n",
    "    try:\n",
    "        # Connect to the database\n",
    "        conn = sqlite3.connect(DATABASE_NAME)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Load face encodings and other information from the database\n",
    "        cursor.execute('''\n",
    "            SELECT name, face_encoding FROM face_data\n",
    "        ''')\n",
    "\n",
    "        rows = cursor.fetchall()\n",
    "        for name, face_encoding in rows:\n",
    "            face_encoding = pickle.loads(face_encoding)\n",
    "            known_face_encodings[name] = face_encoding\n",
    "\n",
    "        # Close the connection\n",
    "        conn.close()\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        print(\"Error while loading known face encodings:\", e)\n",
    "\n",
    "    return known_face_encodings\n",
    "\n",
    "def recognize_person(face_encoding, known_face_encodings):\n",
    "    # Compare the face encoding with known faces (from the loaded array)\n",
    "    for name, known_face_encoding in known_face_encodings.items():\n",
    "        for face in known_face_encoding:\n",
    "            matches = face_recognition.compare_faces([face], face_encoding, tolerance= 0.3)\n",
    "\n",
    "            if any(matches):\n",
    "                return name\n",
    "\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    known_face_encodings = load_known_face_encodings()\n",
    "\n",
    "    # Load Haar Cascade Classifier for face detection\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "    # Start webcam capture\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Convert the frame to grayscale for face detection\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces in the frame\n",
    "        faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            face_encoding = face_recognition.face_encodings(frame, [(y, x + w, y + h, x)])[0]\n",
    "\n",
    "            name = recognize_person(face_encoding, known_face_encodings)\n",
    "            if name:\n",
    "                # Calculate similarity percentage\n",
    "                known_face_encoding_arr = known_face_encodings[name]\n",
    "                for face in known_face_encoding_arr:\n",
    "                    similarity_scores = face_recognition.face_distance([face], face_encoding)\n",
    "                    similarity_percentage = (1 - similarity_scores[0]) * 100\n",
    "                    if similarity_percentage > 70:\n",
    "                        color = (90, 255, 0)\n",
    "                        \n",
    "                        try:\n",
    "                            # Connect to the database\n",
    "                            conn = sqlite3.connect(DATABASE_NAME)\n",
    "                            cursor = conn.cursor()\n",
    "\n",
    "                            # Fetch additional information from the database\n",
    "                            cursor.execute('''\n",
    "                                SELECT age, occupation, email FROM face_data WHERE name=?\n",
    "                            ''', (name,))\n",
    "                            row = cursor.fetchone()\n",
    "\n",
    "                            # Close the connection\n",
    "                            conn.close()\n",
    "\n",
    "                            if row:\n",
    "                                age, occupation, email = row\n",
    "                                # Draw a rectangle around the face\n",
    "                                cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "                                cv2.putText(frame, name, (x, y - 140), cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2)\n",
    "                                cv2.putText(frame, str(age), (x, y -110), cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2)\n",
    "                                cv2.putText(frame, str(occupation), (x, y - 80), cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2)\n",
    "                                cv2.putText(frame, str(email), (x, y -50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2)\n",
    "                                cv2.putText(frame, str(round(similarity_percentage, 2)), (x, y -20), cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2)\n",
    "\n",
    "                        except sqlite3.Error as e:\n",
    "                            print(\"Error while fetching additional information:\", e)\n",
    "                            # time.sleep(10)\n",
    "                            \n",
    "                        break\n",
    "                    else:\n",
    "                        color = (0, 0, 255)\n",
    "                        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "                        # cv2.putText(frame, \"Unknown Face\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2)\n",
    "                        # cv2.putText(frame, str(similarity_percentage), (x, y + 20), cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2)\n",
    "                        \n",
    "\n",
    "        # Show the frame\n",
    "        cv2.imshow(\"Webcam\", frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rough Snippet Testing Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\olami\\Documents\\E Process\\DS_ML_AI\\Computer Vision\\AI-Enabled Image Search and Conversation Assistant\\prototype_2_faceRecog.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/olami/Documents/E%20Process/DS_ML_AI/Computer%20Vision/AI-Enabled%20Image%20Search%20and%20Conversation%20Assistant/prototype_2_faceRecog.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# import pickle\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/olami/Documents/E%20Process/DS_ML_AI/Computer%20Vision/AI-Enabled%20Image%20Search%20and%20Conversation%20Assistant/prototype_2_faceRecog.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m image_folder \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mKnown_Faces/Olamide/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/olami/Documents/E%20Process/DS_ML_AI/Computer%20Vision/AI-Enabled%20Image%20Search%20and%20Conversation%20Assistant/prototype_2_faceRecog.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m image_paths \u001b[39m=\u001b[39m [os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(image_folder, image) \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(image_folder) \u001b[39mif\u001b[39;00m image\u001b[39m.\u001b[39mlower()\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.jpg\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/olami/Documents/E%20Process/DS_ML_AI/Computer%20Vision/AI-Enabled%20Image%20Search%20and%20Conversation%20Assistant/prototype_2_faceRecog.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(image_paths[\u001b[39m0\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/olami/Documents/E%20Process/DS_ML_AI/Computer%20Vision/AI-Enabled%20Image%20Search%20and%20Conversation%20Assistant/prototype_2_faceRecog.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39marray(face_recognition\u001b[39m.\u001b[39mface_encodings(img)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# import pickle\n",
    "image_folder = \"Known_Faces/Olamide/\"\n",
    "image_paths = [os.path.join(image_folder, image) for image in os.listdir(image_folder) if image.lower().endswith('.jpg')]\n",
    "img = cv2.imread(image_paths[0])\n",
    "print(np.array(face_recognition.face_encodings(img)))\n",
    "\n",
    "my_face_encoding = face_recognition.face_encodings(img, face_recognition.face_locations(img))\n",
    "# print(my_face_encoding)\n",
    "\n",
    "known_face_encodings = {}\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(DATABASE_NAME)\n",
    "cursor = conn.cursor()\n",
    "# Load face encodings and other information from the database\n",
    "cursor.execute('''\n",
    "    SELECT name, face_encoding FROM face_data\n",
    "''')\n",
    "\n",
    "rows = cursor.fetchall()\n",
    "for name, face_encoding in rows:\n",
    "    face_encoding = pickle.loads(face_encoding)\n",
    "    known_face_encodings[name] = face_encoding\n",
    "    \n",
    "print(known_face_encodings)\n",
    "# # for name, known_face_encoding in known_face_encodings.items():\n",
    "# #     for face in known_face_encoding:\n",
    "# #         # print([face])\n",
    "# #     # print(f\"{name}\\n{known_face_encoding}\")\n",
    "# #     # break\n",
    "    \n",
    "# known_face_encoding_arr = known_face_encodings[name]\n",
    "# # Close the connection\n",
    "# conn.close()\n",
    "\n",
    "# for f in known_face_encoding_arr:\n",
    "#     similarity = face_recognition.face_distance(f, my_face_encoding)\n",
    "#     print(similarity)\n",
    "#     print(np.array(my_face_encoding).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
