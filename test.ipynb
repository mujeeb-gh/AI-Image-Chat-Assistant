{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence: 37.01\n",
      "Confidence: 36.51\n",
      "Confidence: 47.11\n",
      "Confidence: 39.92\n",
      "Confidence: 39.87\n",
      "Confidence: 43.74\n",
      "Confidence: 38.54\n",
      "Confidence: 37.12\n",
      "Confidence: 39.15\n",
      "Confidence: 39.73\n",
      "Confidence: 38.65\n",
      "Confidence: 38.43\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "\n",
    "def get_face_embeddings(image_path):\n",
    "    image = face_recognition.load_image_file(image_path)\n",
    "    face_encodings = face_recognition.face_encodings(image)\n",
    "\n",
    "    if len(face_encodings) > 0:\n",
    "        return face_encodings[0]  # Return the first face encoding (assumes one face per image)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def compare_faces(known_face_encoding, unknown_face_encoding):\n",
    "    # Compute the Euclidean distance between the two face embeddings\n",
    "    similarity_score = face_recognition.face_distance([known_face_encoding], unknown_face_encoding)[0]\n",
    "\n",
    "    # Normalize the similarity score to a range between 0.3 and 0.8\n",
    "    # normalized_confidence = 0.3 + (similarity_score - 0) * (0.8 - 0.3) / (1 - 0)\n",
    "\n",
    "    # return normalized_confidence\n",
    "    return similarity_score\n",
    "\n",
    "def main():\n",
    "    # Load known face embedding\n",
    "    known_image_path = \"Known_Faces/Tolu2.jpg\"\n",
    "    known_face_encoding = get_face_embeddings(known_image_path)\n",
    "    if known_face_encoding is None:\n",
    "        print(\"No face detected in the known image.\")\n",
    "        return\n",
    "\n",
    "    # Start webcam capture\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Get face encoding of the current frame\n",
    "        face_locations = face_recognition.face_locations(frame)\n",
    "        if len(face_locations) > 0:\n",
    "            face_encoding = face_recognition.face_encodings(frame, face_locations)[0]\n",
    "\n",
    "            # Compare faces\n",
    "            confidence = compare_faces(known_face_encoding, face_encoding)\n",
    "            confidence = (1 - confidence)*100\n",
    "            print(f\"Confidence: {confidence:.2f}\")\n",
    "            \n",
    "            if confidence >= 70:\n",
    "              color = (0, 255, 0)\n",
    "            else:\n",
    "              color = (0, 0, 255)\n",
    "\n",
    "            # Draw rectangle and confidence level on the frame\n",
    "            top, right, bottom, left = face_locations[0]\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), color, 2)\n",
    "            cv2.putText(frame, f\"Confidence: {confidence:.2f}\", (left, bottom + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "        # Show the frame\n",
    "        cv2.imshow(\"Webcam\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "\n",
    "# Dictionary with predefined information for known individuals\n",
    "known_people = {\n",
    "    \"Tolu2\": {\n",
    "        \"age\": 30,\n",
    "        \"occupation\": \"Software Engineer\",\n",
    "        \"contact\": \"john.doe@example.com\"\n",
    "    },\n",
    "    \"Ola\": {\n",
    "        \"age\": 25,\n",
    "        \"occupation\": \"Data Scientist\",\n",
    "        \"contact\": \"jane.smith@example.com\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def recognize_person(face_encoding, known_face_encodings):\n",
    "    # Compare the face encoding with known faces\n",
    "    for name, known_face_encoding in known_face_encodings.items():\n",
    "        matches = face_recognition.compare_faces([known_face_encoding], face_encoding)\n",
    "\n",
    "        if any(matches):\n",
    "            return name, known_people[name]\n",
    "\n",
    "    return None, None\n",
    "\n",
    "def main():\n",
    "    # Load known face encodings and names\n",
    "    known_face_encodings = {}\n",
    "    for name in known_people.keys():\n",
    "        image_path = f\"Known_Faces/{name.replace(' ', '_')}.jpg\"  # Assuming images are stored in the 'known_faces' folder\n",
    "        image = face_recognition.load_image_file(image_path)\n",
    "        face_encoding = face_recognition.face_encodings(image)[0]\n",
    "        known_face_encodings[name] = face_encoding\n",
    "\n",
    "    # Start webcam capture\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Find face locations and encodings in the frame\n",
    "        face_locations = face_recognition.face_locations(frame)\n",
    "        face_encodings = face_recognition.face_encodings(frame, face_locations)\n",
    "\n",
    "        for face_encoding, (top, right, bottom, left) in zip(face_encodings, face_locations):\n",
    "            name, info = recognize_person(face_encoding, known_face_encodings)\n",
    "            if name and info:\n",
    "                # Calculate similarity percentage\n",
    "                similarity_score = face_recognition.face_distance([known_face_encodings[name]], face_encoding)[0]\n",
    "                similarity_percentage = (1 - similarity_score) * 100\n",
    "\n",
    "                # Draw a rectangle around the face\n",
    "\n",
    "                # Display the person's information if similarity is greater than 80%\n",
    "                if similarity_percentage > 60:\n",
    "                    color = (0, 255, 0)\n",
    "                    # text = f\"{name}\\nAge: {info['age']}\\nOccupation: {info['occupation']}\\nContact: {info['contact']}\"\n",
    "                    cv2.putText(frame, name, (left, bottom + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "                    cv2.putText(frame, f\"Age: {info['age']}\", (left, bottom + 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "                    cv2.putText(frame, f\"Occupation: {info['occupation']}\", (left, bottom + 70), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "                    cv2.putText(frame, f\"Contact: {info['contact']}\", (left, bottom + 90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "                else:\n",
    "                    color = (0, 69, 255)\n",
    "                    \n",
    "                \n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), color, 2)\n",
    "\n",
    "                # Display the similarity percentage on the frame\n",
    "                cv2.putText(frame, f\"Similarity: {similarity_percentage:.2f}%\", (left, bottom - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "            \n",
    "        # Show the frame\n",
    "        cv2.imshow(\"Webcam\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'input_face.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m api \u001b[39m=\u001b[39m tweepy\u001b[39m.\u001b[39mAPI(auth)\n\u001b[0;32m     13\u001b[0m \u001b[39m# Load and encode the input face image\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m input_face_image \u001b[39m=\u001b[39m face_recognition\u001b[39m.\u001b[39;49mload_image_file(\u001b[39m\"\u001b[39;49m\u001b[39minput_face.jpg\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     15\u001b[0m input_face_encoding \u001b[39m=\u001b[39m face_recognition\u001b[39m.\u001b[39mface_encodings(input_face_image)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     17\u001b[0m \u001b[39m# Search Twitter profiles with profile pictures\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\olami\\anaconda3\\lib\\site-packages\\face_recognition\\api.py:86\u001b[0m, in \u001b[0;36mload_image_file\u001b[1;34m(file, mode)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_image_file\u001b[39m(file, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     79\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[39m    Loads an image file (.jpg, .png, etc) into a numpy array\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[39m    :return: image contents as numpy array\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m     im \u001b[39m=\u001b[39m PIL\u001b[39m.\u001b[39;49mImage\u001b[39m.\u001b[39;49mopen(file)\n\u001b[0;32m     87\u001b[0m     \u001b[39mif\u001b[39;00m mode:\n\u001b[0;32m     88\u001b[0m         im \u001b[39m=\u001b[39m im\u001b[39m.\u001b[39mconvert(mode)\n",
      "File \u001b[1;32mc:\\Users\\olami\\anaconda3\\lib\\site-packages\\PIL\\Image.py:3227\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3224\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[0;32m   3226\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[1;32m-> 3227\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   3228\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   3230\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input_face.jpg'"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "\n",
    "# Authenticate with Twitter API\n",
    "consumer_key = \"Dhzcc5ewCrrg1ZYVeCUM8tSD3\"\n",
    "consumer_secret = \"uu1ilepwkP1Wve9TlG9BzVJA3rkkaKcgTsk90AmCx8VAeUJyNF\"\n",
    "\n",
    "access_token = \"1390026603225305094-HyyOPObjqOJCARhySI9oZoXOXWXZYP\"\n",
    "access_token_secret = \"hplNyOZ2we9KrlYryxkH4fipfeRpdHO6cBOFzIyeaTVy6\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# Load and encode the input face image\n",
    "input_face_image = face_recognition.load_image_file(\"input_face.jpg\")\n",
    "input_face_encoding = face_recognition.face_encodings(input_face_image)[0]\n",
    "\n",
    "# Search Twitter profiles with profile pictures\n",
    "best_match_profile = None\n",
    "best_similarity_score = 0.0\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search_users, q=\"filter:has:profile_image\").items():\n",
    "    profile_image_url = tweet.profile_image_url.replace(\"_normal\", \"\")  # Use original resolution image\n",
    "    profile_image = face_recognition.load_image_file(profile_image_url)\n",
    "    profile_face_encoding = face_recognition.face_encodings(profile_image)[0]\n",
    "    \n",
    "    similarity_score = face_recognition.face_distance([input_face_encoding], profile_face_encoding)[0]\n",
    "    \n",
    "    if similarity_score > best_similarity_score:\n",
    "        best_similarity_score = similarity_score\n",
    "        best_match_profile = tweet\n",
    "\n",
    "# Display the best match profile information\n",
    "if best_match_profile:\n",
    "    print(\"Best Match Profile:\")\n",
    "    print(\"Twitter Username:\", best_match_profile.screen_name)\n",
    "    print(\"Profile Image URL:\", best_match_profile.profile_image_url)\n",
    "    print(\"Similarity Score:\", best_similarity_score)\n",
    "else:\n",
    "    print(\"No matching profileÂ found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
